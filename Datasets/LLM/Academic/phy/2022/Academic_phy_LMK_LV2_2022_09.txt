Title: Quantifying Interdependence in Deep Representations using Gaussian Mixture Mutual Information for Interpretable Phylogenetic Inference

Abstract:
Deep learning models have revolutionized various fields, including phylogenetics. However, understanding the complex representations learned by these models remains a challenge. To address this, we adapt GMM-MI, a mutual information estimation algorithm, to quantify the interdependence between latent representations and input features in deep phylogenetic inference models. By leveraging Gaussian Mixture Models, GMM-MI provides a robust and interpretable measure of mutual information. We integrate GMM-MI into a deep learning framework for phylogenetic inference, enabling the analysis of representation learning and feature importance. Our results demonstrate that GMM-MI facilitates the identification of salient features driving phylogenetic predictions, thereby enhancing model interpretability. Furthermore, we show that GMM-MI can be used to compare the representation learning strategies employed by different deep learning models, providing insights into their relative strengths and weaknesses. This work contributes to the development of more transparent and explainable deep learning models for phylogenetic inference in the era of big data (2022).