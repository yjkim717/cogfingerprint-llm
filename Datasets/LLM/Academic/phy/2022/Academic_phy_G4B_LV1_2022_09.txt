Hereâ€™s an academic abstract inspired by the provided summary, suitable for a physics research paper and adhering to the specified constraints:

**Abstract**

The increasing reliance on deep learning within complex physical simulations necessitates improved methods for quantifying feature dependencies and enhancing model interpretability. This work introduces a novel estimator, termed GMM-MI, leveraging Gaussian Mixture Models (GMMs) to approximate mutual information (MI) between latent representations learned by deep neural networks. Traditional MI estimation techniques often struggle with high-dimensional data and complex non-linear relationships prevalent in physical datasets. GMM-MI provides a statistically grounded approach, utilizing GMMs to model the marginal and conditional distributions of the latent space, thereby facilitating a more accurate and computationally efficient MI calculation. We demonstrate the efficacy of GMM-MI across simulated datasets exhibiting non-Gaussian characteristics, suggesting its potential to improve the understanding of emergent behaviors within deep learning models applied to physical systems. Validation against established methods highlights the robustness of this representation learning technique.