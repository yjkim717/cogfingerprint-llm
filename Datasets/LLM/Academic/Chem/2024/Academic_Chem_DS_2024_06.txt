In the domain of computational chemistry, the development of machine learning force fields (MLFFs) has emerged as a transformative approach for accelerating molecular dynamics (MD) simulations, which are traditionally limited by the computational expense of ab initio methods. This study introduces a novel surrogate modeling framework, termed Dynamical Feature Transfer (DFT-MD), designed to circumvent redundant electronic structure calculations by intelligently reutilizing quantum-mechanical descriptors from temporally adjacent configurations. By leveraging the inherent smoothness of molecular trajectories on the potential energy surface, our method constructs a predictive model that significantly reduces the number of required force evaluations per simulation. Benchmark calculations on condensed-phase systems and biomolecules demonstrate that DFT-MD achieves an order-of-magnitude computational speedup—up to 9.5×—compared to conventional ML-driven MD, while rigorously preserving the fidelity of the resultant Boltzmann distribution and thermodynamic observables. This advancement not only enhances the feasibility of simulating larger systems and longer timescales but also provides a generalizable strategy for optimizing the trade-off between computational cost and predictive accuracy in next-generation molecular modeling.