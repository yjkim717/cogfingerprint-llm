The development of transferable machine-learned force fields (MLFFs) that achieve ab initio accuracy while maintaining stability in molecular dynamics (MD) simulations remains a central challenge in computational chemistry. Current approaches often require extensive, system-specific training data and exhibit limited generalizability across diverse chemical spaces. Here, we introduce a unified neural network potential architecture, pre-trained on a comprehensive multi-material dataset encompassing organic molecules, inorganic solids, and aqueous systems. This model functions as a foundational platform that captures robust quantum-mechanical interactions, enabling high-fidelity MD simulations with minimal task-specific fine-tuning. We demonstrate its performance across several challenging benchmarks, including reactive chemistry in solution, phase transitions in materials, and biomolecular conformational sampling. The foundation model consistently reproduces structural, dynamic, and thermodynamic properties with density functional theory-level accuracy while achieving a >1000-fold computational speedup. By significantly reducing the data requirements for new systems while ensuring numerical stability over microsecond-scale simulations, this approach provides a transformative tool for accelerating materials discovery and molecular design across previously inaccessible spatiotemporal scales.