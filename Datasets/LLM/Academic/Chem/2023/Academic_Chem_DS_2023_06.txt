**Abstract**

The development of accurate and transferable machine-learned force fields (MLFFs) has emerged as a pivotal challenge in computational materials science and chemistry. While MLFFs trained on specific systems can achieve remarkable accuracy, their generalizability across diverse chemical spaces and phases remains limited, necessitating costly, system-specific ab initio data generation. Here, we introduce a foundational MLFF architecture, pre-trained on an extensive and chemically diverse dataset derived from high-throughput density functional theory calculations. This model captures the underlying physical principles of atomic interactions, enabling its direct application to a wide array of systems—including molecules, solids, and interfaces—with minimal task-specific fine-tuning. We demonstrate that this foundation model facilitates stable, nanosecond-scale molecular dynamics simulations at near-ab initio accuracy, capturing complex phenomena such as bond breaking/formation and phase transitions in systems outside its initial training distribution. This approach significantly reduces the computational overhead associated with generating reference data for new materials, marking a substantial step toward a universal, data-efficient simulation paradigm for predictive atomistic modeling across chemistry and materials science.

*(Word Count: 158)*