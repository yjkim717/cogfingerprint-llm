Okay, here's an original abstract inspired by the provided keywords and summary, written in a formal, academic style suitable for a bio/medical journal, and contextualized to 2023. I’ve aimed for approximately 422 words and structured it with a clear introduction, methods, results, and conclusion.  I've also included some potential journal-specific phrasing to enhance its suitability.

---

**Direct Observation of Procedural Skills (DOPS) as a Formative Assessment Tool in Obstetrics and Gynecology Resident Training: A Mixed-Methods Evaluation**

**Abstract**

**Background:** The acquisition of technical proficiency in obstetrics and gynecology (OBGY) requires rigorous training and ongoing assessment. Traditional assessment methods often rely on summative evaluations, potentially overlooking opportunities for real-time feedback and targeted skill development. Direct Observation of Procedural Skills (DOPS) represents a potentially valuable approach to formative assessment, allowing for immediate guidance and iterative improvement. However, the widespread adoption of DOPS in OBGY residency programs requires robust evaluation of its feasibility and impact on learner and educator perceptions.

**Methods:** This prospective, mixed-methods study investigated the implementation and perceived value of a standardized DOPS program within a single, university-affiliated OBGY residency program.  Data were collected over a 12-month period (January – December 2023) involving 24 OBGY residents (PGY1-PGY4) and 15 attending physicians actively involved in resident education.  Quantitative data were gathered using a validated, structured observation form (adapted from the Dartmouth Assessment of Procedural Skills - DAPS) to assess resident performance across core OBGY procedures, including vaginal delivery, Cesarean section, and endometrial biopsy.  Data points included technical skills (e.g., instrument handling, tissue manipulation), efficiency, and adherence to best practices.  Formative feedback was provided to residents immediately following each observation.  Qualitative data were obtained through semi-structured interviews with residents (n=12) and faculty (n=8) exploring their perceptions of DOPS utility, workload impact, and suggestions for program optimization. Interview transcripts were analyzed using thematic analysis to identify recurring patterns and key themes. Statistical analysis included descriptive statistics and paired t-tests to compare pre- and post-DOPS observation scores for selected procedures.

**Results:** Quantitative analysis revealed a statistically significant improvement (p < 0.05) in average procedural performance scores for residents undergoing DOPS, indicating demonstrable skill enhancement over the study period.  Qualitative analysis identified three key themes: (1) *Enhanced Learning*: Residents reported increased self-awareness of technical deficits and a greater appreciation for targeted feedback. Faculty perceived DOPS as a valuable tool for identifying and addressing individual resident learning needs. (2) *Feasibility and Workload*: While faculty acknowledged an initial time investment in DOPS implementation, they ultimately perceived the benefits of improved resident competence outweighed the additional effort. Resident participation was consistently high, with minimal complaints regarding scheduling. (3) *Program Refinement*: Both residents and faculty suggested incorporating standardized checklists and refining the observation form to better align with program-specific learning objectives.

**Conclusion:**  This study provides compelling evidence supporting the utility of DOPS as a formative assessment tool in OBGY residency training.  The observed improvements in procedural skills, coupled with positive perceptions from both residents and faculty, suggest that structured DOPS programs can