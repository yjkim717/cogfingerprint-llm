 Here's a formal academic-style abstract, inspired by the provided summary and keywords, suitable for a computer science publication in 2020:

**Abstract**

Estimating Gaussian mixture models (GMMs) in high-dimensional spaces remains a computationally challenging problem, particularly when confronted with outliers or corrupted data. This paper introduces a novel polynomial-time algorithm for robust GMM estimation, addressing a long-standing open problem in robust statistics. Our approach leverages tensor decomposition techniques within a sum-of-squares framework to achieve resilience against a substantial proportion of erroneous data points. Unlike existing iterative methods susceptible to divergence or requiring restrictive distributional assumptions, the proposed algorithm guarantees convergence and provides accurate parameter estimates even under significant data corruption.  The computational complexity is bounded by a polynomial function of the number of data points and the mixture components (k), facilitating its application to large-scale datasets. Experimental results demonstrate the algorithmâ€™s superior performance compared to traditional methods in the presence of noise, establishing a significant advance in robust machine learning.