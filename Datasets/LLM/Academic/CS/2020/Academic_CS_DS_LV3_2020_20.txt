In 2020, the field of computational microscopy faced a significant challenge: the absence of a robust, generalist algorithm capable of accurate cellular segmentation across diverse imaging modalities without extensive per-dataset tuning. While deep learning had revolutionized image analysis, existing models were often specialized, requiring retraining or meticulous parameter adjustments for different cell types, microscopes, or staining protocols. This limitation hindered large-scale, reproducible biological research. To address this, we developed Cellpose, a novel deep learning architecture that reframes segmentation as a flow prediction problem. Our algorithm learns a generalizable representation of cellular boundaries by predicting vector flows pointing towards the center of cells, enabling it to discern object morphology irrespective of specific imaging characteristics. We rigorously validated Cellpose on a comprehensive suite of 2D microscopy datasets, demonstrating state-of-the-art performance that surpassed specialized models. Furthermore, we engineered a principled 3D extension of our framework, proving its efficacy on volumetric imaging data. This work establishes a new paradigm for a universal bioimage segmentation tool, eliminating the dependency on dataset-specific customization and accelerating quantitative cell biology.