Okay, here's an original abstract inspired by the provided keywords and summary, written in a formal, academic style suitable for a CS conference proceeding, and framed within a 2020 context.  I've aimed for precision and a logical flow.

---

**Contrastive Mutual Information Maximization for Unpaired Image-to-Image Translation**

Unpaired image-to-image translation aims to learn a mapping between two image domains without requiring corresponding image pairs. Existing approaches often rely on adversarial training or cycle consistency, which can be sensitive to hyperparameter tuning and prone to mode collapse. This paper introduces a novel framework leveraging contrastive learning to address these limitations. Our method, Contrastive Mutual Information Maximization (CMIM), explicitly maximizes the mutual information between corresponding patches in the input and output images, encouraging the learned feature space to encode shared semantic information across domains. Unlike cycle consistency, CMIM does not enforce strict reconstruction, allowing for greater flexibility in the translation process.  We formulate a contrastive objective that pulls feature representations of aligned patches from the input and output domains closer while pushing apart those from unaligned patches. Experimental results on benchmark datasets demonstrate that CMIM achieves state-of-the-art performance in terms of both visual quality and semantic fidelity compared to existing unpaired image-to-image translation techniques. Furthermore, CMIM exhibits improved robustness to variations in dataset characteristics and reduced sensitivity to adversarial attacks, suggesting enhanced generalization capabilities.  We believe this work provides a promising direction for developing more stable and effective unpaired image-to-image translation models.

---

**Key elements I incorporated to meet the prompt's requirements:**

*   **Formal Language:** Used precise terminology (e.g., "semantic fidelity," "mode collapse," "adversarial attacks," "feature representations").
*   **Structured Reasoning:**  Started with the problem, introduced the proposed solution (CMIM), explained *how* it works (mutual information maximization, contrastive objective), described the benefits (better results, robustness), and concluded with a statement of significance.
*   **CS Field Specific:** Focused on concepts common in computer vision and machine learning (image translation, contrastive learning).
*   **2020 Context:** The language and framing reflect the state of the field around 2020, referencing common challenges like adversarial training instability and the popularity of contrastive learning methods.  The emphasis on robustness and generalization also aligns with trends in that era.
*   **Length:**  The abstract is within the typical 200-word range for a conference abstract.
*   **Keywords Addressed:** All keywords from the original prompt were implicitly or explicitly incorporated.



Let me know if you'd like me to refine this further or explore a different angle!