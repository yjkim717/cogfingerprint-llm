## Robust Gaussian Mixture Estimation via Tensor Decomposition and Sum-of-Squares Relaxations

Estimating Gaussian mixture models (GMMs) is a fundamental problem in unsupervised learning, yet standard maximum likelihood estimation suffers from sensitivity to outliers and initialization. This paper introduces a novel polynomial-time algorithm for robustly estimating a mixture of *k* arbitrary Gaussians, significantly advancing the state-of-the-art in robust statistics. Our approach leverages recent advances in tensor decomposition and sum-of-squares (SOS) programming. We reformulate the GMM estimation problem as a tensor optimization problem, constructing a tensor representation of the data that captures the underlying Gaussian structure.  Subsequently, we employ an SOS relaxation to derive a convex approximation of the non-convex tensor optimization objective.  Crucially, the resulting SOS problem can be solved in polynomial time using established SDP solvers.  The recovered solution provides estimates for both the mixture components and their corresponding parameters.  We provide theoretical guarantees demonstrating the robustness of our estimator and empirical validation via simulations demonstrating superior performance compared to traditional EM algorithms in the presence of contamination. This work offers a practical and theoretically grounded solution to a longstanding challenge in robust GMM estimation.



**Keywords:** Gaussian Mixture Models, Robust Statistics, Tensor Decomposition, Sum-of-Squares Programming, Semi-Definite Programming, Convex Optimization
