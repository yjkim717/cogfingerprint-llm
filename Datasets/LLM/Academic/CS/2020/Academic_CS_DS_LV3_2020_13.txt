**Abstract**  
Contemporary natural language processing (NLP) systems demonstrate remarkable proficiency in modeling lexical similarity, yet their capacity to represent human-like word meaning remains fundamentally limited. This limitation stems from a critical absence of grounding in perceptual, motor, and intentional experiences—cornerstones of human cognition as elucidated by psychological theories of conceptual representation. While distributional semantic models excel at capturing statistical regularities in text, they operate in a disembodied symbolic space, detached from the sensory-motor interactions and goal-directed behaviors that shape conceptual development in humans. Consequently, such systems struggle with meaning nuances tied to physical experience, social context, and dynamic intentionality. To bridge this gap, we argue for integrating computationally explicit mechanisms of grounding—drawing on multimodal data, embodied simulations, and intentional frameworks—into NLP architectures. Such an approach promises not only more robust and context-aware language technologies but also deeper computational insights into the cognitive underpinnings of human semantic knowledge.