**Abstract**

Software documentation, specifically the quality of in-code comments, significantly impacts developer productivity and maintainability. This paper introduces a novel approach to comment enhancement leveraging established readability metrics and iterative feedback loops.  Utilizing the 2020 methodology, a tool was developed to assess the readability of software comments based on established indices such as the Flesh Reading Ease score and measures of word-finding query difficulty.  The core innovation lies in integrating programmer and student feedback – collected through targeted questionnaires – to refine comment content and style. 

Preliminary results demonstrate a positive correlation between improved comment readability, as determined by the tool, and subsequent user reports of increased clarity and reduced cognitive load when interacting with the code.  Specifically, comments exhibiting higher Flesh Reading Ease scores were consistently associated with lower word-finding query difficulty.  This research contributes to the growing body of work on software readability, advocating for a data-driven approach to documentation practices. Future work will explore the tool’s efficacy across diverse programming languages and project scales, alongside a deeper investigation into the specific comment types most responsive to readability interventions.