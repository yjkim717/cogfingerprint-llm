Title: Revisiting Word Meaning Representations: A Comparative Analysis of Human Cognition and NLP Systems

Abstract:
The quest for human-like linguistic competence in natural language processing (NLP) systems has sparked a critical examination of word meaning representations. As of 2020, despite significant advancements in deep learning techniques, NLP systems continue to grapple with capturing the nuances of human word meaning. This study undertakes a comparative analysis of word meaning representations in humans and machines, shedding light on the cognitive models that underlie human linguistic competence. Our findings indicate that current NLP systems, reliant on distributional semantics and vector space models, fall short in emulating the complex, context-dependent, and cognitively grounded representations of word meaning inherent to human cognition. This disparity underscores the need for more sophisticated cognitive models that integrate multimodal and embodied cognition to bridge the gap between human and machine linguistic understanding.