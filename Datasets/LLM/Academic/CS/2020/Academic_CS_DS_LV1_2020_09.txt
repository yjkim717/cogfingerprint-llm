Of course. Here is an original, formal academic abstract inspired by the provided summary, contextualized for the year 2020.

***

**Abstract**

The efficacy of in-line code comments is contingent upon their readability, yet this dimension of software documentation is often overlooked. While established readability metrics, such as the Flesch Reading Ease (FRE) score, are prevalent in assessing prose, their application to the constrained, domain-specific lexicon of source code comments remains underexplored. This paper presents the design and empirical evaluation of a novel automated tool, `ReadAid`, which integrates real-time readability analysis into the integrated development environment (IDE). `ReadAid` leverages a suite of readability formulas, adapted for technical terminology, to provide developers with immediate feedback and refactoring suggestions for their comments. A controlled user study (N=85) was conducted to assess the tool's impact, partitioning participants into novice and expert cohorts. Results indicate a statistically significant improvement in comment comprehension and reduced cognitive load for novice programmers when using `ReadAid`-generated suggestions. Conversely, the tool demonstrated a negligible effect on the performance and practices of experienced developers, suggesting that expertise may mitigate the influence of formal readability metrics. These findings underscore the potential of automated readability tooling as a pedagogical aid for computer science education and junior developer onboarding, while highlighting the complex interplay between textual complexity and programmer experience.