 Here's a formal academic-style abstract inspired by the provided summary and keywords, suitable for a CS publication in 2020, aiming for approximately 161 words:

**Abstract**

Deep learning has demonstrated remarkable capabilities in modeling complex temporal dependencies; however, ensuring the stability of learned dynamics models remains a critical challenge, particularly when deployed in safety-critical applications. This paper presents a novel framework for learning deep dynamics models with guaranteed stability properties. Our approach jointly learns a systemâ€™s dynamics, represented by a deep neural network, alongside a Lyapunov function that enforces non-expansiveness across the entire state space. By integrating Lyapunov stability theory with deep learning techniques, we provide a rigorous guarantee against divergence, a common issue in learned dynamics. We formulate the learning problem as a constrained optimization, where the neural network parameters are updated to minimize prediction error while simultaneously satisfying the Lyapunov inequality. Experimental results, conducted on benchmark dynamical systems, demonstrate the efficacy of our method in learning stable dynamics models and achieving improved generalization compared to existing approaches. This work contributes a foundational step towards certifiably safe and reliable deep learning-based control and prediction.