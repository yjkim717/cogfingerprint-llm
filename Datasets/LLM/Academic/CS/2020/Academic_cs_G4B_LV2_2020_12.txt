**Abstract:**

Recent advances in deep generative models have demonstrated remarkable capabilities in simulating complex phenomena. However, ensuring the stability and predictability of these models, particularly when representing dynamical systems, remains a significant challenge. This work addresses this limitation by presenting a novel framework for learning stable deep dynamics models. We introduce a methodology leveraging Lyapunov functions to guarantee non-expansive mapping properties within the learned modelâ€™s dynamics.  Specifically, our approach employs deep dynamics models trained to approximate the evolution dictated by a learned Lyapunov function, thereby implicitly enforcing stability.  Experimental validation demonstrates the efficacy of this technique in achieving stable learning across diverse dynamical systems, mitigating the risk of unbounded trajectories often associated with conventional deep generative approaches.  This research contributes to the burgeoning field of controllable deep learning, offering a pathway towards reliable simulation and prediction of complex, time-dependent systems.