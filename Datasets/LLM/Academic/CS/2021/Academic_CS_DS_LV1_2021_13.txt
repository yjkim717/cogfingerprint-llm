**Abstract**

While multimodal neural networks have demonstrated proficiency in learning word-referent mappings from cross-situational statistics, their alignment with human cognitive biases remains limited. This paper investigates the capacity of such models to replicate the mutual exclusivity (ME) biasâ€”a cognitive constraint where humans preferentially assign a novel label to a novel, rather than a familiar, object. We posit that standard neural architectures, trained via maximum likelihood estimation on co-occurrence data, inherently lack the inductive biases necessary to exhibit robust ME. To address this, we propose a structured regularization framework that explicitly penalizes the model for assigning high probability to multiple labels for a single referent. Our experiments on a series of controlled cross-situational learning tasks demonstrate that while baseline models capture only a weak statistical tendency toward ME, our regularized model exhibits a stronger, more human-like bias. These results suggest that integrating explicit cognitive constraints is crucial for developing neural models that not only learn from data but also align with fundamental principles of human language acquisition. This work underscores the importance of marrying data-driven learning with structured, model-based biases in computational cognitive science.