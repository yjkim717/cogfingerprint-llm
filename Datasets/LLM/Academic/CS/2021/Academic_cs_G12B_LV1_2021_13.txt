)
## Abstract: Bridging the Gap: Evaluating Multimodal Neural Networks in Cross-Situational Word Learning

Cross-situational word learning (CSWL) represents a fundamental cognitive ability enabling infants to map novel words to objects based on repeated observation of linguistic and visual contexts. Recent computational approaches have explored the potential of multimodal neural networks to model this process, leveraging their capacity to learn distributed representations and complex visual-linguistic mappings. This work investigates the extent to which contemporary multimodal neural network architectures can replicate key behavioral findings in CSWL, specifically focusing on the role of the mutual exclusivity constraint â€“ the tendency to assume that objects have unique names. We trained and evaluated several recurrent and transformer-based multimodal networks on simulated CSWL environments, manipulating factors such as object visual distinctiveness and linguistic contextual diversity. Our results demonstrate that these networks can successfully acquire word-object associations in scenarios with relatively high visual distinctiveness and limited linguistic overlap, exhibiting performance consistent with human learning trajectories. However, we observed a significant deficit in their ability to effectively leverage the mutual exclusivity principle when faced with ambiguous visual input or competing linguistic cues. This highlights a critical limitation: current network architectures, while proficient in learning correlations, struggle to fully implement the abstract, constraint-based reasoning characteristic of human CSWL. We conclude by discussing potential avenues for future research, including the incorporation of symbolic reasoning modules and explicit mutual exclusivity priors, to further close the gap between computational models and human cognitive processes in CSWL.




