This paper investigates differentially private algorithms for correlation clustering under the constraint of pure differential privacy. We establish a fundamental limitation by proving a novel linear additive error lower bound for any pure differentially private mechanism in this unsupervised learning setting. Complementing this impossibility result, we present an efficient algorithm achieving subquadratic additive error under approximate differential privacy, thereby demonstrating a provable separation between these privacy regimes. Our work delineates the inherent cost of strong privacy guarantees in clustering correlated data.