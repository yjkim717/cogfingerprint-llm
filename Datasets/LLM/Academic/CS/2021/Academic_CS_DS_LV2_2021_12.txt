In this work, we address the critical challenge of adversarial robustness in deep neural networks by proposing a novel method to enforce orthogonality in convolutional layers via the Cayley transform. Orthogonal layers inherently control the Lipschitz constant of the network, which is fundamental for certified defense against norm-bounded adversarial perturbations. While prior approaches have explored orthogonality in fully-connected layers, their extension to convolutions remains non-trivial. Our method parameterizes convolutional filters within the Stiefel manifold, ensuring strict orthogonality and promoting stable, distance-preserving transformations throughout the network. We rigorously evaluate our approach on standard image classification benchmarks under ℓ₂-norm-bounded attacks. Empirical results demonstrate that our Cayley-orthogonal convolutional networks significantly enhance certified robust accuracy compared to existing baselines, without compromising clean performance. This establishes a principled and effective pathway toward building certifiably robust deep learning models, advancing the frontier of reliable machine learning systems.