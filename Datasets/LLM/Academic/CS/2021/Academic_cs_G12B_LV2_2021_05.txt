)
## Re-evaluating Fairness Through Inequality and Power Lenses in Algorithmic Decision-Making

Traditional algorithmic fairness interventions often rely on group-level parity metrics, implicitly assuming a level playing field and neglecting the embedded societal inequalities that shape data and outcomes. This paper argues that such approaches provide an incomplete and potentially misleading assessment of algorithmic impact, particularly within contexts of existing power asymmetries. We introduce a critical framework that explicitly incorporates concepts of inequality and power into the evaluation of algorithmic fairness, moving beyond equilibrium-based notions. Through theoretical analysis and empirical demonstration, we illustrate how seemingly fair algorithms, as judged by standard metrics, can nonetheless exacerbate or perpetuate systemic disadvantages when viewed through these alternative lenses. Specifically, we leverage causal inference techniques to model the interplay between pre-existing inequalities, algorithmic decision-making, and downstream consequences, revealing how disparate impacts can arise even when group parity is achieved. Our findings highlight the limitations of current fairness definitions and advocate for a shift towards methodologies that account for power dynamics and structural inequalities when designing and deploying algorithmic systems. We conclude by outlining directions for future research focused on developing fairness interventions sensitive to these critical considerations, ultimately aiming to promote more equitable and just algorithmic outcomes in 2021 and beyond.