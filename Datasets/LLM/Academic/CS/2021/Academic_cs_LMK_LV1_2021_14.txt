Title: Comparative Analysis of PPO and SAC for Multi-Vehicle Collision Avoidance in Autonomous Driving using Reinforcement Learning

Abstract:

The increasing complexity of autonomous driving scenarios necessitates the development of efficient collision avoidance systems. This study investigates the efficacy of two prominent reinforcement learning algorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), in enabling multiple autonomous vehicles to avoid collisions. We formulate the collision avoidance problem as a Markov Decision Process (MDP) and train both PPO and SAC agents in a simulated environment with varying traffic densities. Our results show that both algorithms can successfully learn collision avoidance strategies, with SAC outperforming PPO in terms of convergence rate and robustness to environmental uncertainties. The SAC agent demonstrated a 25% reduction in collision rates compared to PPO in high-density traffic scenarios. Our findings suggest that SAC is a more suitable algorithm for real-world autonomous driving applications, where reliability and adaptability are crucial. The insights gained from this study can inform the development of more sophisticated collision avoidance systems for autonomous vehicles.