**Abstract**

Recent advances in adversarial machine learning have highlighted the vulnerability of convolutional neural networks (CNNs) to subtle input perturbations. Traditional defenses often rely on empirical adjustments, lacking theoretical grounding and generalizability. This work presents a novel approach to directly parameterize orthogonal convolutional layers via the Cayley transform, offering a principled method for enhancing both adversarial robustness and model scalability. We demonstrate that leveraging Cayley parameterization allows for explicit control over Lipschitz constants within the convolutional layers, a crucial factor in ensuring robustness against adversarial attacks.  Furthermore, the transform facilitates a more compact and efficient representation of these layers, addressing a significant limitation of existing orthogonal convolution implementations.  Our analysis, grounded in Fourier domain convolution, reveals a clear connection between Cayley parameterization, Lipschitz continuity, and improved adversarial resilience.  Experimental results on benchmark datasets showcase a substantial improvement in robustness against gradient-based attacks, while maintaining competitive performance on clean data, suggesting a promising direction for developing inherently secure and scalable CNN architectures.