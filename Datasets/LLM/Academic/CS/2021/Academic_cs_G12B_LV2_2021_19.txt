)
## Abstract: Copy-Blend Augmentation for Enhanced Low-Level Vision Tasks

The increasing demand for robust and efficient deep learning models in low-level vision tasks, such as image enhancement and denoising, frequently encounters limitations imposed by the availability of large, labeled datasets. This paper investigates the efficacy of copy-blend augmentation – a data augmentation technique that seamlessly integrates textural information from distinct images – as a means of mitigating this data scarcity. We hypothesize that copy-blend augmentation, by preserving perceptual consistency during data expansion, can improve the generalization capability of models trained on limited datasets. Our experimental results, conducted on standard image enhancement benchmarks, demonstrate that copy-blend augmentation consistently outperforms traditional augmentation strategies and baseline training approaches. Specifically, we observe significant improvements in both quantitative metrics (PSNR, SSIM) and qualitative perceptual quality assessments. Furthermore, we analyze the impact of varying blend parameters, identifying optimal configurations that maximize performance. The findings suggest that copy-blend augmentation presents a promising avenue for enhancing low-level vision models, offering a pathway towards reduced reliance on extensive training data and improved robustness in real-world scenarios. This research contributes to the broader understanding of data augmentation techniques and their impact on the performance of deep learning architectures.
