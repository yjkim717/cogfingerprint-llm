Title: Comparative Analysis of PPO and SAC for Centralized Collision Avoidance in Autonomous Vehicles

Abstract:
The increasing prevalence of autonomous vehicles necessitates efficient collision avoidance strategies. This study evaluates the performance of two prominent reinforcement learning algorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), within a centralized control framework for multiple autonomous vehicles. Conducted in a simulated environment, our experiments assess the efficacy of PPO and SAC in preventing collisions while optimizing vehicle trajectories. The results indicate that both algorithms achieve satisfactory collision avoidance rates, with SAC demonstrating superior performance in complex scenarios due to its maximum entropy framework. Conversely, PPO exhibits more stable convergence properties in simpler environments. Our findings contribute to the ongoing discourse on the applicability of reinforcement learning in autonomous vehicle control, highlighting the trade-offs between exploration-exploitation strategies in PPO and SAC. The insights garnered from this research inform the development of robust collision avoidance systems for autonomous vehicles.