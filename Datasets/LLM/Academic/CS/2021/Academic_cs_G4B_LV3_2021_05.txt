Here’s an academic abstract inspired by the provided summary and keywords, suitable for a 2021 publication in Computer Science:

**Abstract**

Contemporary algorithmic decision-making practices frequently prioritize notions of “fairness” without adequately addressing the underlying dynamics of inequality and power. This paper, building upon critiques of traditional fairness metrics, argues for a paradigm shift in algorithmic auditing.  Current approaches often fail to recognize that disparities may be legitimately rooted in meritocratic distinctions, and crucially, neglect the significant heterogeneity *within* defined groups. Furthermore, the pervasive influence of power structures – both explicit and implicit – is routinely absent from assessments of algorithmic impact. We posit that a more robust evaluation necessitates incorporating causal inference techniques to disentangle the effects of algorithmic design from pre-existing social inequalities.  Specifically, we advocate for analyses that explicitly model the distribution of power and its relationship to algorithmic outcomes, moving beyond simplistic notions of group-level fairness to expose systemic biases. This revised framework offers a critical lens for responsible AI development, promoting accountability and mitigating unintended consequences.