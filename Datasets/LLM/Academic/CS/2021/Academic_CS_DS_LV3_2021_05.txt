In 2021, computational approaches to fairness in algorithmic decision-making face mounting scrutiny for their narrow focus on distributive outcomes. This paper argues that prevailing fairness metrics, rooted in meritocratic ideals, inadvertently legitimize structural inequalities by abstracting decisions from their causal socio-historical context. Drawing on causal inference methods, we demonstrate how such frameworks obscure power asymmetries embedded in training data and optimization objectives. We propose a paradigm shift toward inequality-aware auditing that explicitly models power dynamics and historical disadvantage. By formalizing mechanisms through which algorithms perpetuate or exacerbate existing hierarchies, our approach enables more meaningful interventions. This reconceptualization moves beyond technical fairness to question the legitimacy of underlying merit standards, offering a critical foundation for equitable computational systems in high-stakes domains.