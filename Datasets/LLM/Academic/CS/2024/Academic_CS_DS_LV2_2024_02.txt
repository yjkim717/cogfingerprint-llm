In this work, we establish near-optimal statistical query (SQ) lower bounds for the Non-Gaussian Component Analysis (NGCA) problem under minimal moment-matching conditions, substantially advancing the theoretical understanding of computational-statistical trade-offs in high-dimensional structured learning. Prior hardness results for NGCA critically relied on stringent chi-squared norm constraints, which inherently limited their applicability to broader distributional settings. By developing novel analytical techniques that circumvent this requirement, we demonstrate that the moment-matching condition alone suffices to prove strong SQ lower bounds for detecting hidden subspaces in non-Gaussian distributions. Our results reveal that the computational hardness of NGCA is more fundamental than previously established, persisting even when distributions satisfy only mild moment constraints. This work resolves open questions regarding the necessity of chi-squared conditions in SQ lower bounds and provides new insights into the inherent limitations of efficient algorithms for high-dimensional statistical estimation tasks. The implications extend to robust statistics and unsupervised learning, where similar structural assumptions frequently arise.