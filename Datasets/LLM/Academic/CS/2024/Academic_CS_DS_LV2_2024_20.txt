**Abstract**

In computational microscopy, cellular segmentation accuracy is critically dependent on input image quality. Current approaches predominantly treat image restoration and segmentation as sequential, independent tasks, which can propagate restoration artifacts into downstream analysis. This paper introduces Cellpose3, a framework that bridges this methodological gap through end-to-end training of restoration models explicitly optimized for segmentation performance. Our approach employs a dual-objective loss function that simultaneously maximizes structural similarity to high-quality reference images while minimizing segmentation error when processed by a generalist cellular segmentation network. Evaluations across diverse microscopy modalities demonstrate that Cellpose3 achieves statistically significant improvements in segmentation accuracy for degraded images compared to conventional restoration pipelines (p<0.01), without compromising perceptual fidelity. These findings establish that task-aware image restoration represents a paradigm shift for robust biological image analysis in low-signal environments.