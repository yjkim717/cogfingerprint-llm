Title: Unveiling Polysemanticity in CLIP Neurons through Second-Order Analysis: Implications for Adversarial Robustness

Abstract:
The burgeoning field of multimodal learning has been significantly advanced by the Contrastive Language-Image Pre-training (CLIP) model, which has demonstrated remarkable capabilities in aligning visual and textual representations. However, the interpretability of CLIP neurons remains an open challenge. This paper introduces a novel 'second-order lens' to analyze the effects of CLIP neurons, focusing on their higher-order interactions and polysemantic behavior. By examining the second-order effects of neuron activations, we reveal complex, non-linear relationships between seemingly unrelated concepts. Our analysis exposes the polysemantic nature of CLIP neurons, wherein individual neurons respond to multiple, distinct semantic features. Furthermore, we demonstrate that this understanding enables the generation of targeted adversarial examples, shedding light on the model's vulnerabilities. Our findings have significant implications for the development of more robust and interpretable multimodal models, and we discuss potential applications in improving adversarial robustness and neuron interpretability in CLIP and beyond.