This paper investigates the paradigm shift in data augmentation methodologies driven by recent advances in generative language models. We analyze how foundation models have transcended traditional perturbation-based techniques to enable semantic-aware synthetic data generation across unimodal and cross-modal domains. The study systematically categorizes augmentation strategies according to their underlying learning frameworksâ€”distinguishing between supervised, self-supervised, and reinforcement learning paradigms. Furthermore, we examine critical challenges including distribution preservation, bias amplification, and evaluation metrics for augmented data quality. As multimodal architectures become increasingly prevalent, we discuss emergent techniques for cross-modal knowledge transfer and their implications for data-scarce domains. This research provides a comprehensive framework for understanding next-generation augmentation systems while identifying promising directions for future work in trustworthy synthetic data generation.