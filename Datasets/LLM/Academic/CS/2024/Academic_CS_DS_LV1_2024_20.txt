**Abstract**

The proliferation of automated microscopy has generated vast datasets, yet their quantitative analysis is often impeded by image degradation from factors such as noise, blur, and low contrast, which challenge conventional cellular segmentation algorithms. While specialized restoration and segmentation models exist, they typically operate in isolation, leading to cascading errors. This paper introduces a unified, end-to-end framework that reframes image restoration as a segmentation-centric optimization problem. We propose a novel architecture wherein a restoration network is adversarially trained not only to maximize perceptual fidelity but also to produce feature representations that are optimally discriminative for a downstream, generalist segmentation model. Our results on diverse, degraded microscopy datasets demonstrate that this co-designed approach significantly outperforms sequential application of state-of-the-art restoration and segmentation tools. The system is packaged as a robust, one-click solution, substantially enhancing the accuracy and accessibility of high-throughput biological image analysis by directly addressing the domain shift introduced by common image artifacts.