**Abstract**

The interpretability of vision-language models remains challenging due to polysemantic neurons—individual units activating for disparate concepts. This paper introduces a second-order lens methodology for interpreting CLIP's visual encoder neurons, extending beyond primary activations to analyze how feature responses modulate under contextual variation. We demonstrate that many neurons exhibit polysemantic behavior, encoding multiple unrelated semantic features that primary attribution methods obscure. By quantifying interaction effects between spatial locations and semantic contexts, our approach reveals these compositional roles. Leveraging these insights, we construct targeted semantic adversarial examples that exploit identified polysemantic alignments, causing consistent misclassifications by perturbing secondary—rather than primary—neuron associations. Furthermore, we show these interpretations enable more semantically-grounded zero-shot segmentation through neuron-concept mapping refinement. Our findings suggest second-order analysis provides a necessary complement to existing interpretability paradigms, offering both vulnerability characterization and performance enhancement pathways for multimodal architectures.