**Abstract**  
Recent advances in machine vision have been profoundly shaped by the proliferation of deep learning architectures, enabling unprecedented capabilities in visual understanding. This paper surveys key developments in object detection, semantic segmentation, and human action recognition, highlighting how convolutional and transformer-based models have redefined performance benchmarks. We address persistent challenges in terminology standardization across subdomains, which often impede interdisciplinary collaboration and reproducible research. Furthermore, the integration of multimodal data and self-supervised learning paradigms is discussed as an emerging trend, offering scalable solutions for annotation-scarce scenarios. Ethical considerations, including bias mitigation and real-time deployment constraints, are also examined in the context of societal integration. By synthesizing contemporary research and identifying unresolved gaps, this analysis aims to guide future innovation in robust, interpretable, and efficient machine vision systems.