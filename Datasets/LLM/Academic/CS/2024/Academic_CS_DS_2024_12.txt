The rapid proliferation of high-resolution Earth observation platforms has precipitated a paradigm shift in geospatial data analysis, with deep learning architectures emerging as the cornerstone for automated feature extraction. This paper examines contemporary advances in multimodal instance-aware detection frameworks tailored for remote sensing imagery. We investigate how heterogeneous data streams—spanning multispectral, synthetic aperture radar, and hyperspectral modalities—are being fused within unified neural network topologies to address the unique challenges of geospatial object detection, including extreme class imbalance, multi-scale contextual dependencies, and complex background clutter. Particular emphasis is placed on transformer-based architectures and their hybrid variants, which have demonstrated remarkable capabilities in capturing long-range spatial relationships critical for precise instance segmentation in cluttered environments. The discussion further explores how these architectures are being adapted to maintain robustness across varying spatial resolutions and imaging conditions, while addressing the critical need for explainable AI in high-stakes environmental monitoring applications. This synthesis aims to provide researchers with a comprehensive understanding of current methodological frontiers and persistent challenges in scaling these approaches for operational deployment in global observation systems.