Title: Mitigating Dimensional Collapse in Non-Contrastive Siamese Representation Learning for Continual Self-Supervised Learning

Abstract:
Non-contrastive self-supervised representation learning methods, such as Siamese networks, have gained significant attention for their ability to learn robust representations without labeled data. However, recent studies have highlighted their sensitivity to model size and dataset, often resulting in dimensional collapse. In this work, we analyze the phenomenon of dimensional collapse in non-contrastive Siamese representation learning and propose a novel metric, Collapse Index (CI), to quantify its extent. Our analysis reveals that dimensional collapse is a significant bottleneck in achieving robust representations, particularly in continual learning scenarios. To address this, we introduce a simple yet effective regularization technique, dubbed Dimensional Regularization (DR), which encourages the learned representations to maintain a stable dimensionality. Our experiments on benchmark datasets demonstrate that DR significantly mitigates dimensional collapse and improves the performance of non-contrastive Siamese representation learning methods in continual self-supervised learning settings. Our results provide a promising direction for future research in this area, with potential applications in real-world continual learning tasks. (2022)