)
## Black-Box Prompt Optimization for Language Model as a Service

**Abstract:** The increasing accessibility of Language Model as a Service (LMaaS) platforms has spurred considerable interest in prompt engineering as a means of tailoring model behavior without requiring access to internal model parameters. While manual prompt crafting remains a prevalent approach, it is often sub-optimal and lacks systematic exploration of the prompt space. Gradient-based methods, while offering potential for automated optimization, are frequently infeasible in LMaaS settings due to the black-box nature of the service, precluding gradient access. This paper introduces a novel, derivative-free optimization framework specifically designed for black-box prompt tuning within LMaaS environments. Our approach leverages a robust search strategy to efficiently navigate the prompt space, iteratively refining prompts based on observed performance metrics. We demonstrate the efficacy of our framework by applying it to the task of [mention specific task if known, otherwise: a representative natural language generation task] using the RoBERTa model hosted via a standard LMaaS API. Empirical results demonstrate that our black-box prompt tuning method significantly outperforms both manual prompt engineering and existing gradient-based optimization techniques adapted for black-box scenarios. This work contributes a practical and effective solution for optimizing LMaaS model performance, enabling researchers and practitioners to unlock the full potential of these powerful language models without requiring internal model access, a significant advancement in 2022.