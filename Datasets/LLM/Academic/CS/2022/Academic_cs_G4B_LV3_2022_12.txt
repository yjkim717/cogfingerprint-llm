Here’s an academic abstract inspired by the provided summary and keywords, suitable for a 2022 publication:

**Abstract**

Recent advancements in computer vision have largely attributed the efficacy of Vision Transformers (ViT) to architectural innovations. However, the pervasive use of patch embeddings remains a critical component. This study challenges this dominant narrative by introducing the ConvMixer, a novel convolutional architecture designed to rival ViT’s performance while maintaining a significantly reduced computational footprint. Through extensive experimentation on the ImageNet dataset, we demonstrate that the ConvMixer achieves comparable, and in some cases superior, accuracy to ViT and other prevalent transformer-based models. Our analysis suggests that the ConvMixer’s success stems from a refined convolution mechanism that effectively captures long-range dependencies, mitigating the need for the global attention inherent in ViT.  These findings indicate that carefully designed convolutional approaches, rather than solely relying on transformer architectures, can provide a viable and efficient pathway toward state-of-the-art vision performance in 2022.