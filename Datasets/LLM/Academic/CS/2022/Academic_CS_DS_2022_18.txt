**Abstract**

The escalating complexity of multi-agent autonomous driving systems necessitates robust control policies capable of preempting catastrophic failure modes, particularly high-speed chain collisions. While traditional model-based methods struggle with the combinatorial state-space and partial observability of real-world traffic, Deep Reinforcement Learning (DRL) offers a promising, data-driven alternative for learning emergent, collision-mitigating behaviors. This research investigates the efficacy of on-policy actor-critic algorithms, specifically tailored for the multi-agent chain collision avoidance problem, framed as a decentralized partially observable Markov decision process (Dec-POMDP). We posit that the primary challenge lies not merely in single-agent obstacle avoidance but in learning implicit communication and cooperative strategies that propagate safety-critical information through a vehicular platoon.

Our methodology involves a multi-stage training regimen in a high-fidelity simulation environment. We first train a baseline policy in a single-agent setting against scripted adversarial agents to establish fundamental evasion capabilities. Subsequently, we transition to a multi-agent environment where all vehicles are controlled by independent instances of the same DRL agent, enabling the emergence of cooperative behaviors such as coordinated braking and lane-change cascades to absorb shockwaves. The policy is optimized using a shaped reward function that penalizes unsafe headways, high deceleration forces on following vehicles, and ultimately, any collision. We evaluate safety efficiency through metrics including collision rate, the severity of impact forces in unavoidable incidents, and string stability of the vehicle platoon under perturbation. Our 2022 findings indicate that a well-tuned multi-agent DRL approach can significantly reduce the probability of chain reaction events compared to a system of independently acting intelligent drivers, highlighting a critical pathway toward enhancing resilience in dense autonomous traffic scenarios.