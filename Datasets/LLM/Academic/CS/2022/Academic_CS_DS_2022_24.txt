This study examines the impact of performance-driven evaluation frameworks on instructional practices in large-scale educational systems. Drawing on survey data from educators within a national computer science curriculum, we investigate how standardized assessments influence teaching methodologies and resource allocation priorities. Results indicate that while instructors acknowledge the motivational benefits of such evaluative mechanisms, they also report significant pressure to align instruction with assessment metrics, a phenomenon characterized as instructional narrowing. Furthermore, educators advocate for leveraging performance data to optimize the distribution of computational resources and targeted professional development in emerging technologies. These findings underscore the dual nature of accountability systems in CS education, highlighting the tension between quality assurance and pedagogical autonomy. The study contributes to ongoing discourse on evidence-based educational policy in technologically evolving environments.