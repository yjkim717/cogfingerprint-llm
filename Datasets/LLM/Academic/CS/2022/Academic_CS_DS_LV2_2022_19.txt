Of course. Here is a formal academic abstract reflecting the provided summary, contextualized for the year 2022.

***

**Abstract**

The performance of computer vision systems in real-world environments is critically dependent on robust image quality under dynamic illumination. Existing High Dynamic Range (HDR) imaging and enhancement methods often struggle with extreme lighting variations, leading to loss of detail in over-exposed and under-exposed regions, while many deep learning-based solutions are computationally prohibitive for edge deployment. To address this, we propose a novel, lightweight two-stage algorithm for HDR image enhancement. The first stage leverages a Fourier Adversarial Network (FAN) to perform illumination-aware correction directly in the frequency domain, enabling efficient global structure recovery and artifact suppression. The refined output is then processed by a second stage comprising a lightweight Convolutional Neural Network (CNN), which performs local texture enhancement and color constancy adjustment, effectively emulating and optimizing segments of a traditional Image Signal Processing (ISP) pipeline. Our experiments demonstrate that the proposed method significantly outperforms existing state-of-the-art techniques in both qualitative visual metrics and quantitative benchmarks, while maintaining a minimal computational footprint. This work validates the efficacy of frequency-domain adversarial learning combined with efficient spatial processing for achieving superior perceptual quality in challenging lighting conditions, paving the way for more reliable vision systems on resource-constrained platforms.