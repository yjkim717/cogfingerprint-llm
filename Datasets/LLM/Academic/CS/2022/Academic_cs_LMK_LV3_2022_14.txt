Title: Enhancing Autonomous Vehicle Safety through Deep Reinforcement Learning: A Chain Collision Avoidance Framework

Abstract:

The escalating deployment of autonomous vehicles (AVs) on public roads necessitates the development of sophisticated driving strategies to mitigate the risk of chain collisions, a phenomenon where multiple vehicles collide in sequence. This study proposes a novel deep reinforcement learning (DRL) based framework for AVs to effectively avoid chain collisions in both single-agent and multi-agent environments. By formulating the driving task as a Markov Decision Process (MDP), we leverage the capabilities of actor-critic algorithms to optimize the AV's decision-making process. The proposed DRL framework enables AVs to learn from interactions with the environment, adapt to various traffic scenarios, and execute evasive maneuvers to prevent chain collisions.

Our analysis demonstrates that the proposed framework significantly enhances the safety efficiency of AVs in various traffic settings. Simulation results show that the DRL-based driving strategy outperforms traditional rule-based approaches in avoiding chain collisions, particularly in multi-agent environments where multiple AVs interact. Furthermore, our study highlights the importance of considering the stochastic nature of traffic dynamics and the interactions between AVs and human-driven vehicles in designing effective collision avoidance systems. The findings of this research contribute to the advancement of AV safety and have implications for the development of more sophisticated DRL-based driving strategies in the pursuit of realizing fully autonomous transportation systems by 2022 and beyond.