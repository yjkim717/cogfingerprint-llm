**Abstract**

The proliferation of Language-Model-as-a-Service (LMaaS) platforms, which provide inference-only API access, presents a significant challenge for gradient-based prompt optimization techniques. To address this, we introduce a novel framework for Black-Box Prompt Tuning (BBPT) that conceptualizes the discrete prompt space as a continuous, low-dimensional manifold. Our method leverages derivative-free optimization (DFO), specifically a covariance matrix adaptation evolution strategy, to iteratively refine a soft prompt vector. This approach operates solely on the model's input-output behavior, circumventing the need for internal gradients or architectural modifications. Empirical evaluations on benchmark natural language understanding tasks demonstrate that BBPT consistently outperforms both manually engineered prompts and gradient-based fine-tuning in the black-box setting. These results affirm the hypothesis that effective prompt optimization is achievable under severe access constraints by exploiting the intrinsic low dimensionality of the prompt utility landscape, establishing a robust and practical paradigm for leveraging proprietary large language models.