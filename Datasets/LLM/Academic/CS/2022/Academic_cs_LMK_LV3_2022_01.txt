Title: Mitigating Dimensional Collapse in Non-Contrastive Siamese Networks for Continual Self-Supervised Representation Learning

Abstract:
Non-contrastive Siamese representation learning has emerged as a prominent paradigm in self-supervised learning, yet its efficacy is often hampered by dimensional collapse and sensitivity to model size. This study provides a rigorous analysis of these limitations, revealing that dimensional collapse precipitates a degradation in representation quality, particularly in the context of continual learning. To address this challenge, we introduce a novel metric, dubbed Representation Degradation Index (RDI), which forecasts downstream task performance by quantifying the extent of dimensional collapse. Our empirical evaluations demonstrate that RDI accurately predicts task performance across various benchmarks. Furthermore, we propose a simple yet effective augmentation strategy that mitigates dimensional collapse by promoting orthogonal representation learning. Our results show that this approach improves the robustness of non-contrastive Siamese networks to model size variations, yielding state-of-the-art performance in continual self-supervised representation learning tasks.