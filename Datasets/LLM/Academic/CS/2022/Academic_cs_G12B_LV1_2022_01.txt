## Abstract: Mitigating Dimensional Collapse in Non-Contrastive Self-Supervised Learning via Continual Adaptation

Self-supervised representation learning (SSL) has emerged as a powerful paradigm for pre-training deep neural networks, offering significant advantages in scenarios with limited labeled data. Recent advances in non-contrastive SSL methods, exemplified by SimSiam, have demonstrated impressive performance while eschewing the need for explicit negative samples. However, these methods are susceptible to a critical failure mode: dimensional collapse, wherein the learned representations collapse to a low-dimensional subspace, negating the benefits of self-supervision. This work investigates the relationship between dataset scale, model capacity, and the propensity for dimensional collapse within non-contrastive SSL frameworks. Our empirical analysis, conducted in 2022, reveals a strong dependency of collapse vulnerability on both factors, highlighting that smaller datasets and larger models exacerbate the issue. Crucially, we demonstrate that incorporating a continual learning paradigm, specifically through incremental adaptation to evolving data streams, effectively mitigates dimensional collapse. This adaptation introduces a dynamic regularization effect, preventing the model from settling into degenerate solutions. We argue that continual learning provides a robust mechanism for maintaining representational diversity and ensuring the efficacy of non-contrastive SSL, particularly in resource-constrained and evolving environments.
