In 2022, the persistent challenge of dynamic illumination in computational photography necessitated robust image signal processing (ISP) pipelines capable of preserving perceptual data integrity. This paper introduces a novel, lightweight two-stage framework for high dynamic range (HDR) imaging, engineered to enhance visual quality for downstream perception tasks under volatile lighting. The proposed methodology leverages Fourier adversarial networks to model and correct illumination artifacts directly in the frequency domain, enabling more efficient feature learning and superior generalization compared to conventional spatial-domain approaches. The first stage performs coarse illumination normalization, while the second stage refines texture and color fidelity. We integrate this algorithm into a streamlined ISP pipeline, demonstrating its computational efficiency on resource-constrained platforms. Quantitative and qualitative evaluations on benchmark datasets confirm that our method significantly outperforms existing techniques in mitigating over-exposure and noise, thereby improving the input quality for critical computer vision applications such as object detection and semantic segmentation. This work establishes that frequency-based adversarial learning is a pivotal direction for developing next-generation, perception-aware imaging systems.