Title: Enhancing Autonomous Vehicle Safety: A Deep Reinforcement Learning Approach to Mitigating Chain Collisions

Abstract:

The advent of autonomous vehicles (AVs) has brought forth a paradigm shift in the automotive industry, promising improved safety and efficiency. However, the risk of chain collisions remains a pressing concern, particularly in high-density traffic scenarios. To address this challenge, we propose a novel driving strategy leveraging deep reinforcement learning (DRL) to enable AVs to navigate complex traffic environments while minimizing the likelihood of chain collisions. Our approach formulates the driving task as a Markov Decision Process (MDP), where the AV's actions are optimized using an actor-critic algorithm. Specifically, we employ a Deep Deterministic Policy Gradient (DDPG) framework, which integrates a critic network to estimate the action-value function and an actor network to generate optimal control policies. The proposed DRL-based driving strategy is evaluated in a simulated traffic environment, where we demonstrate its efficacy in avoiding chain collisions and reducing the severity of potential crashes. Our results show that the proposed approach achieves a significant reduction in collision rates compared to traditional rule-based driving strategies. Furthermore, we analyze the safety efficiency of our approach under various traffic conditions, including different density levels and vehicle speed distributions. Our findings suggest that the proposed DRL-based driving strategy can effectively enhance AV safety, providing a promising solution for mitigating chain collisions in real-world traffic scenarios. The proposed framework has the potential to be integrated into AV systems, contributing to the development of safer and more efficient transportation systems.