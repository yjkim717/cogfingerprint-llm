Here's a formal academic-style abstract based on the provided summary, suitable for a CS publication in 2022:

**Abstract**

Recent advancements in self-supervised learning (SSL) have demonstrated the efficacy of non-contrastive Siamese representation learning approaches, such as SimSiam, in learning meaningful feature embeddings without reliance on negative samples. However, empirical observations suggest a critical vulnerability: these methods are susceptible to *dimensional collapse*, a phenomenon wherein the learned representations converge to a low-dimensional subspace, hindering downstream task performance. This work investigates the sensitivity of non-contrastive SSL to both dataset scale and model capacity, demonstrating a strong correlation between these factors and the propensity for collapse. To address this, we introduce a novel *collapse metric* – a quantitative measure assessing the degree of representation degeneracy – capable of predicting downstream performance on various classification tasks. Our analysis highlights the importance of careful hyperparameter tuning and architectural choices in mitigating collapse and ensuring robust feature learning.  Furthermore, we discuss the implications of these findings for continual learning scenarios, where catastrophic forgetting can be exacerbated by collapsed representations. This research contributes to a deeper understanding of the stability and generalizability of non-contrastive SSL techniques.
