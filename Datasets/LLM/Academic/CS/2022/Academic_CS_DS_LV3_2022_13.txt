**Abstract**

Recent advances in grounded language learning have highlighted critical limitations in neural networks' capacity for systematic generalizationâ€”the ability to comprehend and produce novel combinations of known linguistic elements. This paper investigates the synergistic role of architectural modularity and strategic data augmentation in addressing this fundamental challenge. Drawing on the theoretical framework proposed by Lake (2022), we demonstrate that explicitly structured modular networks, when coupled with comprehensive augmentation protocols, induce compositional representations that transcend training distribution boundaries. Our empirical analysis, conducted using the gSCAN benchmark suite, reveals that this integrated approach facilitates robust generalization by enforcing functional separation between perceptual processing and linguistic inference modules. Quantitative results substantiate performance improvements exceeding 70% on systematic generalization metrics compared to monolithic architectures. These findings establish that inductive biases, instantiated through both model architecture and data diversity, are prerequisite for human-like compositional understanding in embodied AI systems. The study provides a foundational framework for developing language-capable agents that generalize systematically beyond their training environments.