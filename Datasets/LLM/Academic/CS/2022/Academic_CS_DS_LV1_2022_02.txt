**Abstract**

The problem of efficiently learning halfspaces under Massart noise—where an adversary may flip labels with a known, instance-specific probability bounded away from 1/2—has remained a central open question in computational learning theory. While information-theoretically solvable, the existence of a computationally efficient PAC learning algorithm has been elusive. This work establishes a significant computational barrier for this problem. We demonstrate that, under the widely believed Learning With Errors (LWE) assumption, no polynomial-time algorithm can PAC learn homogeneous halfspaces with Massart noise at a rate η and achieve misclassification error better than Ω(η). Our result employs a sophisticated reduction that transforms a hard LWE instance into a distribution over labeled examples that inherently exhibits Massart noise at a level proportional to the LWE error rate. Any learner achieving a classification error significantly below this threshold could be leveraged to solve the underlying LWE problem, thereby violating the cryptographic assumption. This finding provides a compelling explanation for the observed difficulty in designing efficient, noise-tolerant learning algorithms for this setting and aligns the complexity landscape for Massart halfspaces with other cryptographically hard learning problems.