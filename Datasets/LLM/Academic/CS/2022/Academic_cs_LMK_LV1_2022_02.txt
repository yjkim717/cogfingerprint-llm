Title: Computational Hardness of PAC Learning Halfspaces with Massart Noise

Abstract:
We establish the computational hardness of PAC learning halfspaces in the presence of Massart noise, a widely studied noise model where the label noise is bounded but adversarial. Assuming the subexponential-time hardness of the Learning With Errors (LWE) problem, we show that no efficient algorithm can PAC learn halfspaces to accuracy better than some constant under Massart noise. Our result relies on a reduction from LWE to the problem of PAC learning halfspaces with Massart noise, leveraging the intricate connections between lattice problems and halfspace learning. This work strengthens the existing evidence that PAC learning halfspaces with Massart noise is computationally intractable, highlighting the inherent challenges in designing robust learning algorithms. Our findings contribute to the understanding of the computational limits of learning in noisy environments, with implications for the development of noise-tolerant machine learning algorithms. (2022)