Here's an academic abstract inspired by the provided summary and keywords, written in a formal style suitable for a CS publication (circa 2022):

**Abstract**

Recent advancements in vision architectures have largely been dominated by Vision Transformers (ViTs), which leverage self-attention mechanisms for image recognition. However, the computational complexity and data requirements of ViTs remain significant challenges. This paper introduces the ConvMixer, a novel architecture that challenges the prevailing transformer-centric paradigm by proposing a remarkably simple convolutional alternative. ConvMixer operates directly on image patches, employing a sequence of spatially separable convolutions and MLP layers, effectively mimicking the patch embedding and attention-like operations found in ViTs, but without reliance on attention mechanisms. Experimental results on standard image recognition benchmarks demonstrate that ConvMixer achieves competitive performance with ViTs and other established convolutional networks, while maintaining comparable model sizes and training data efficiency. These findings suggest that carefully designed convolutional operations can effectively capture global dependencies in images, offering a computationally efficient and potentially more scalable alternative to transformer-based approaches for image classification.