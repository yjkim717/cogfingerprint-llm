Title: Enhancing Autonomous Vehicle Safety: A Deep Reinforcement Learning Approach to Chain Collision Avoidance

Abstract:

The advent of autonomous vehicles (AVs) has underscored the imperative for sophisticated collision avoidance systems to ensure the safety and reliability of vehicular networks. Chain collisions, in particular, pose a significant threat to road safety, necessitating the development of efficacious strategies for their mitigation. This paper presents a novel deep reinforcement learning (DRL)-based driving strategy to prevent chain collisions in AVs, leveraging the Markov Decision Process (MDP) framework to model the sequential decision-making process. By formulating the collision avoidance problem as an MDP, we enable the application of actor-critic algorithms, a class of model-free reinforcement learning techniques, to derive an optimal control policy. The proposed DRL-based approach integrates the strengths of both policy-based and value-based methods, facilitating efficient exploration of the state-action space and ensuring robust decision-making under uncertainty. Our methodology involves training a deep neural network to approximate the optimal policy, using a carefully designed reward function that balances safety and efficiency considerations. Simulation results demonstrate the efficacy of the proposed strategy in preventing chain collisions, outperforming traditional rule-based approaches. The analysis reveals significant improvements in safety metrics, underscoring the potential of DRL to enhance the reliability of AVs. The findings of this research contribute to the ongoing discourse on the development of intelligent transportation systems, highlighting the promise of DRL in addressing complex safety challenges in autonomous driving.