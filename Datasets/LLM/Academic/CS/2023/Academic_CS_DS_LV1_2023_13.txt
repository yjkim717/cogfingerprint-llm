Of course. Here is an original, formal academic abstract inspired by the provided summary.

***

**Title:** CompoBench: A Meta-Learning Framework for Inducing Systematic Generalization in Neural Sequence Models

**Abstract:**

A fundamental challenge in artificial intelligence is the gap between the robust systematic generalization of humans and the brittle performance of neural networks on compositional tasks. While neural models excel at interpolation, they often fail to extrapolate to novel combinations of known primitives. This paper introduces CompoBench, a meta-learning framework designed to directly optimize for compositional reasoning. We posit that standard supervised learning, with its static data distribution, inadequately prepares networks for the dynamic nature of compositional problem-solving. Instead, CompoBench exposes a model to a curriculum of procedurally generated tasks, where the meta-objective is to minimize loss across a distribution of training episodes, each requiring the composition of a distinct set of learned rules or concepts. Our experiments on a suite of algorithmic and visual reasoning benchmarks demonstrate that models trained with CompoBench significantly outperform conventional baselines. They achieve near-perfect accuracy on held-out primitive combinations, exhibiting human-like extrapolation. These results suggest that structuring the learning process to explicitly reward adaptability to new compositional structures is a critical step toward models that generalize systematically beyond their training data.

**(Word Count: 198)**