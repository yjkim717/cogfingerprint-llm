Title: Enhancing Zero-Shot Image Segmentation with CLIP-based Text-Driven Decomposition

Abstract:
CLIP's image encoder has demonstrated remarkable capabilities in learning robust image representations. However, its performance is often compromised by the presence of spurious features. In this work, we propose a novel text-based decomposition approach that leverages transformer models to refine CLIP's image representations. By decomposing images into semantically meaningful components guided by text prompts, we mitigate the impact of irrelevant features and enhance the model's ability to capture salient objects. Our proposed method enables the creation of a zero-shot image segmenter that can effectively identify and segment objects without requiring task-specific training data. Experimental results demonstrate the efficacy of our approach, outperforming existing zero-shot segmentation methods. By harnessing the power of CLIP and transformer models, our work paves the way for more accurate and efficient image segmentation in various computer vision applications.