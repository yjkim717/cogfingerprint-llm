Title: Capturing Annotator Disagreement in Hate Speech Detection: A Probabilistic Modeling Approach

Abstract:
Hate speech detection, a quintessential subjective task in natural language processing (NLP), is plagued by annotator disagreement, which can significantly impact model performance and reliability. To address this challenge, we propose a novel probabilistic model that predicts annotator ratings on potentially offensive text, thereby capturing the variance in human judgment. By leveraging a Bayesian framework, our model quantifies uncertainty in annotator responses, providing a more nuanced understanding of the subjective nature of hate speech. Experimental results on benchmark datasets demonstrate that our approach outperforms existing methods in terms of predictive accuracy and robustness. Furthermore, our model provides valuable insights into annotator disagreement, enabling a more informed evaluation of hate speech detection systems. Our work has significant implications for the development of more reliable and effective NLP systems for subjective tasks.