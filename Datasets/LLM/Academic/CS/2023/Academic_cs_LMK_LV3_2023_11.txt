Title: Enhancing Deep Clustering with Collision Cross-Entropy: A Robust Alternative to Shannon's Cross-Entropy Loss

Abstract:
Deep clustering has emerged as a pivotal technique in unsupervised learning, leveraging the strengths of deep neural networks to uncover inherent patterns in unlabeled data. However, its performance is often hampered by the limitations of traditional loss functions, particularly Shannon's cross-entropy loss, when dealing with soft class labels. This paper introduces collision cross-entropy as a robust alternative, designed to mitigate the issues associated with Shannon's cross-entropy in the context of soft labels. By adopting collision cross-entropy, we demonstrate a significant improvement in deep clustering performance, as evidenced by our extensive experiments on benchmark datasets. The proposed approach not only enhances clustering accuracy but also fosters a more nuanced understanding of the data distribution. Our findings underscore the potential of collision cross-entropy to redefine the landscape of self-labeled clustering methodologies in 2023.