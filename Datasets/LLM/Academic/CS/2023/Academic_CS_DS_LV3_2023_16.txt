In 2023, real-time multilingual speech processing confronts the dual challenge of maintaining transcription quality while minimizing latency in continuous audio streams. This paper introduces Whisper-Streaming, a novel framework that extends the Whisper architecture for unsegmented long-form speech. By implementing a local agreement policy, our method dynamically aligns partial transcripts through confidence-based segmentation, eliminating dependency on predefined segment boundaries. The core innovation lies in its self-adaptive latency mechanism, which continuously optimizes processing delays in response to acoustic and linguistic features. Evaluations demonstrate that Whisper-Streaming achieves state-of-the-art transcription accuracy across 57 languages while sustaining a 3.3-second end-to-end latency. This represents a significant advancement for live captioning and simultaneous translation systems, balancing computational efficiency with robust performance in diverse operational environments.