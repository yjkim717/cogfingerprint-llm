Here's a formal academic-style abstract inspired by the provided summary and keywords, suitable for a CS publication in 2023:

**Abstract:** Recent advancements in large language models (LLMs) have spurred exploration into their applicability beyond traditional natural language processing tasks. This paper investigates the potential of code-generating LLMs (Code-LLMs) for information extraction (IE), presenting CodeIE, a novel framework that leverages these models to perform named entity recognition (NER) and relation extraction (RE). Unlike conventional approaches relying on fine-tuning or natural language-centric architectures, CodeIE frames IE as a code generation problem, prompting the Code-LLM to produce code snippets that directly extract desired information. Empirical evaluation across several benchmark datasets demonstrates that CodeIE achieves state-of-the-art performance in few-shot IE settings, surpassing both natural language models and traditionally fine-tuned IE systems.  These results highlight the efficacy of code-LLMs as powerful zero- and few-shot IE tools, suggesting a paradigm shift towards generative approaches for structured data extraction and offering a promising avenue for resource-constrained IE applications.
