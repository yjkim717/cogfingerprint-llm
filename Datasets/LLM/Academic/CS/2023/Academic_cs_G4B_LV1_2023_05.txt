Hereâ€™s an abstract inspired by the provided summary, suitable for a 2023 computer science research publication:

**Abstract**

Subjective tasks, particularly hate speech detection, are frequently burdened by inter-annotator disagreement, significantly impacting model performance and generalizability. This work introduces a novel framework for modeling annotator variance within predictive models, leveraging demographic information to mitigate bias and enhance accuracy. We propose a hierarchical Bayesian model that simultaneously predicts individual annotator ratings and aggregates group opinion, explicitly quantifying the uncertainty associated with each prediction.  Crucially, our approach incorporates demographic features as covariates, allowing for the systematic investigation of how annotator disagreement varies across different target groups.  Experimental results on a diverse hate speech dataset demonstrate that incorporating model uncertainty and demographic context substantially reduces annotation discrepancies and improves predictive calibration.  Further analysis reveals a correlation between annotator diversity and disagreement levels, suggesting avenues for targeted training strategies to improve robustness and fairness in hate speech detection systems.