 Here's a formal academic-style abstract, inspired by the provided summary and keywords, suitable for a CS publication in 2023:

**Abstract**

The inherent subjectivity in identifying hate speech presents a significant challenge for Natural Language Processing (NLP) systems. This work addresses the problem of annotator disagreement in hate speech detection by proposing a novel predictive model capable of estimating individual annotator ratings alongside anticipated target group reactions to potentially offensive text. Our approach integrates demographic information of annotators and inferred online content preferences as contextual features, enabling a more nuanced understanding of subjective judgments. The model’s architecture allows for the generation of probabilistic outputs, providing a quantifiable measure of uncertainty in predictions—a crucial element for robust and reliable hate speech detection. Furthermore, we prioritize annotator privacy by employing techniques that avoid direct disclosure of sensitive demographic data while still leveraging its predictive power. Empirical evaluation demonstrates that incorporating these contextual features significantly improves prediction accuracy compared to baseline models. This research contributes a framework for building more transparent and accountable hate speech detection systems, acknowledging the complexities of subjective human assessment and facilitating a more reliable evaluation of model performance in this critical area.