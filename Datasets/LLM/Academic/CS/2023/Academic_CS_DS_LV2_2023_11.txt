Of course. Here is a formal academic abstract based on the provided summary, written from the perspective of a 2023 researcher.

***

**Abstract**

The efficacy of deep clustering and self-labeling frameworks is critically dependent on the quality and robustness of the objective function used to train the underlying neural network. While Shannon's cross-entropy loss is the de facto standard for supervised learning with hard labels, its application to contexts involving soft or pseudo-labels—ubiquitous in self-supervised and unsupervised paradigms—reveals significant vulnerabilities. Specifically, its sensitivity to label noise and miscalibration can lead to confirmation bias and suboptimal feature representations, thereby impeding clustering performance. In this work, we introduce Collision Cross-Entropy (CCE), a novel loss function designed to address these limitations. CCE fundamentally reconsiders the penalty structure for probabilistic predictions, offering enhanced robustness when learning from imperfect, dynamically generated soft labels. We provide a theoretical motivation for CCE, linking its properties to improved optimization landscapes in the presence of label uncertainty. Empirically, we integrate CCE into contemporary deep clustering and self-labeling pipelines, demonstrating its superiority over Shannon's cross-entropy and other robust baselines. Our experiments on standard benchmarks show that models trained with CCE achieve higher clustering accuracy and normalized mutual information (NMI), yielding more semantically coherent clusters. This work establishes CCE as a principled and effective alternative for modern unsupervised representation learning, paving the way for more reliable and scalable self-supervised systems.