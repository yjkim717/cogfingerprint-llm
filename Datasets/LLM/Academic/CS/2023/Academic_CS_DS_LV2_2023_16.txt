This paper introduces Whisper-Streaming, a novel architecture for low-latency, real-time speech recognition. Building upon the robust multilingual capabilities of the Whisper model, we address the critical challenge of latency in live scenarios, such as multilingual conferences. Our method implements optimized streaming inference, achieving a consistent latency of 3.3 seconds. This represents a significant advancement for practical, real-time transcription services, demonstrating that high accuracy and low latency can be concurrently achieved without sacrificing the model's inherent support for diverse languages and accents.