Year: 2024
Author: mikaball
URL: https://www.reddit.com/r/javahelp/comments/192nkl6/inverting_the_second_level_cache_in_a_masterslave/

Let's suppose I'm using Spring/Hibernate framework with a Master/Slave replication DB architecture. I write to the master and read from slaves. I have a not so much acceptable replication latency. What I want is to change the behavior of the Hibernate second level cache to do the following: * Have a version control system for each entity * For every queried entity, always hit the database, even if the entity is on the cache * Return the most recent version to the upper levels and update the cache accordingly This inverts the normal operation of the second level cache, so I don't find any info on how to do this. It has some major advantage: 1. Doesn't hurt much on the horizontal scaling, because the Master/Slave architecture already handles that. 2. Provides instantaneous consistency between write/reads of the same server, and more importantly performed by the same user. This provides a better user experience, since write and read operations (even if performed on a different Hibernate session) are immediately synchronized. For other users replication latency is not important, since they changed nothing, nothing is expected to change. 3. No issues on cache consistency, because the second level is not treated as a source of truth. It always hits the DB, and the database already handles the replication process much better. The whole point is to provide a better user experience with minimal impacts on horizontal scaling. Is there a way to set this up on Spring/Hibernate? EDIT: To dismiss some confusion. The write operations write on the cache after the master commit. The slaves are not updated because they surfer replication delay. The cache on that pod has the most recent value. However, if updates are performed on another pod the cache is incorrect. There's no cache synchronization between pods. **Let's look at an example with the same architecture but without the cache.** The user is bound to a pod with an affinity policy. There are many pods and slaves. The master/slave replication has an exaggerated 30s delay. 1. The user navigates in the UI and performs an update. 2. The update is committed to master. 3. The user navigates to a different UI view that requires the previous data. 4. The server request the data to the slave, but only returns the outdated row. Replication has not yet finished. 5. The user sees the outdated values - "where the fuck is my data?" 6. User waiting... "the fuck is my data?" 7. User goes back and tries to update again and receives an Optimistic Lock exception. 8. User gives up and buys a different software. **Changes with the proposed cache present.** ... 2. The update is committed to master and on the pod cache. ... 4. The server request the data to the slave, but only returns the outdated row (v1). Compares the version from the slave (v1) and local 2LC (v2), returns the cache to the client because it's the current version. 2LC cache is overriding the slave response. ... 7. User goes back and tries to update again... no Optimistic Lock exception because the version of the row is the most updated (not counting with changes performed by other users)
